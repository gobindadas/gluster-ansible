hc-ansible-deployment is end-to-end HC deployment playbook which is using both gluster-ansible role and ovirt-ansible-hosted-engine-setup role.
1. There is one inventory file which is gluster_inventory.yml has gluster related configurations.
   Enable "VDO config" for VDO and disable Non-VDO part.
2. The json file he_gluster_vars.json has Hosted-Engine related configurations for gluster.

Note: # In he_gluster_vars.json file for IPv6 Hosted Engine use 
"he_mount_options": "backup-volfile-servers=host2-backend-network-FQDN:host3-backend-network-FQDN,xlator-option=transport.address-family=inet6"

For new HC deployment both file need to be modified with accurate values like host,device,pvs,vgs,lvs,fqdn,passwords etc

How to run:
 > cd hc-ansible-deployment

 > ansible-playbook -i gluster_inventory.yml hc_deployment.yml --extra-vars='@he_gluster_vars.json'

For gluster deployment clean up:
 > ansible-playbook -i gluster_inventory.yml tasks/gluster_cleanup.yml

Note: Replace appropriate host name with host1,host2 and host3 in inventory file and json file.
ovirt_repo_release_rpm value should be particular release repo if you are installing role from ansible-galaxy
Default is: http://resources.ovirt.org/pub/yum-repo/ovirt-release42-snapshot.rpm

-> The below varables are required only when user wants to install pkgs using subscription-manager.
"ovirt_repositories_ovirt_release_rpm": "http://resources.ovirt.org/pub/yum-repo/ovirt-master-release.rpm"
"ovirt_repositories_use_subscription_manager": false,
"ovirt_repositories_ovirt_version": 4.2,
"ovirt_repositories_target_host": "host1",
"ovirt_repositories_rh_username": "Username to use for subscription manager",
"ovirt_repositories_rh_password": "Password to use for subscription manager",
"ovirt_repositories_pool_ids": ["List of pools ids to subscribe to"],
"ovirt_repositories_pools": ["List of subscription pool names"],
"ovirt_repositories_repos_backup_path": "Directory to backup the original repositories configuration",
"ovirt_repositories_force_register": false,
"ovirt_repositories_rhsm_server_hostname": "Hostname of the RHSM server. By default it's used from rhsm configuration"
 For more details please refer: https://github.com/oVirt/ovirt-ansible-repositories

 Integrate Luks/clevis with Tang:
  Cretate inventory file with ansible-vault create luks_tang-inventory.yml
  Configure luks device and tang server: ansible-playbook -i luks_tang_inventory.yml /etc/ansible/roles/gluster.ansible/playbooks/hc-ansible-deployment/tasks/luks_tang_setup.yml --tags luksencrypt,bindtang --ask-vault-pass

 Integrate Luks/clevis with Tang by blacklisting multipath devices:
  Cretate inventory file with ansible-vault create luks_tang-inventory.yml
  Configure luks device and tang server: ansible-playbook -i luks_tang_inventory.yml /etc/ansible/roles/gluster.ansible/playbooks/hc-ansible-deployment/tasks/luks_tang_setup.yml --tags blacklistdevices,luksencrypt,bindtang --ask-vault-pass

Host replacement:
  Create two inventory:
    1- node_prep_inventory.yml - This inventory contains information about host preparation.
    2- node_replace_inventory.yml - This inventory contains information about node which needs to be replaced and other hosts
There are two tasks:
  1- Gluster host preparation
     This task has tags called "preparehost"
  2- Gluster Peer Membership Restoration
     This task has tags called "restorepeer"
If both operation need to be performed then run:
ansible-playbook -i node_prep_inventory.yml -i node_replace_inventory.yml tasks/replace_node.yml
Or using tags indivisual operation can be performed like:
  ansible-playbook -i node_prep_inventory.yml -i node_replace_inventory.yml tasks/replace_node.yml --tags restorepeer
Or
  ansible-playbook -i node_prep_inventory.yml -i node_replace_inventory.yml tasks/replace_node.yml --tags preparehost

Gluster logical network:
 1- Add appropriate values in gluster_network_inventory.yml
 2- Run playbook with inventory like:
    ansible-playbook -i gluster_network_inventory.yml tasks/gluster_network_setup.yml
